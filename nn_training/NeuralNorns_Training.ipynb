{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlD10mxQsrpA"
      },
      "source": [
        "# NeuralNorns\n",
        "\n",
        "Welcome to the NeuralNorns! NeuralNorns is a machine learning model designed for creating repeating patterns, such as drum beats or arpeggios. The model is based on the autoencoder architecture and can be easily exported to run in P5.js applications, or on the Norns platform.\n",
        "\n",
        "In this tutorial, you will be guided through the following steps:\n",
        "\n",
        "1.   **Data Collection:** Learn how to gather and preprocess the training data to ensure the best results for your patterns.\n",
        "2.   **Model Training:** Understand how to train the NeuralNorns model effectively.\n",
        "3.   **Model Export:** Explore the process of exporting the trained model to different platforms for practical applications.\n",
        "\n",
        "By the end of this tutorial, you'll have the knowledge and tools to create your own mesmerizing repeating patterns with NeuralNorns. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Includes and Helper Functions\n",
        "\n",
        "Before we begin, we must include essential Python libraries and define some custom helper functions.\n",
        "\n",
        "**Click** on the **play button** located in the upper left corner of the code cell below.\n",
        "\n",
        "During execution, you may notice an \"is processing\" animation around the play button. The time taken for execution depends on the complexity of the cell.\n",
        "\n",
        "Once the cell is fully executed, a green tick will appear along with the execution time.\n",
        "\n",
        "Console logs are provided under each cell for a better understanding of the process."
      ],
      "metadata": {
        "id": "ovJji6P2Nh2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP6nv0JvQq8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9804d27-f116-4cc7-99d5-6850984a7f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "great! you executed your first code block!\n"
          ]
        }
      ],
      "source": [
        "# HELPER FUNCTIONS & LIBRARIES\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "import json\n",
        "import time as time\n",
        "\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# converts nested list into nested tuples\n",
        "def to_tuple(lst):\n",
        "  return tuple(to_tuple(i) if isinstance(i, list) else i for i in lst)\n",
        "\n",
        "# converts nested list into set of nested tuples\n",
        "def to_tuple_set(lst):\n",
        "  s = set()\n",
        "  s.update(to_tuple(lst))\n",
        "  return s\n",
        "\n",
        "# converts nested tuples into nested lists\n",
        "def to_list(tpl):\n",
        "  return list(to_list(i) if isinstance(i, tuple) else i for i in tpl)\n",
        "\n",
        "print(\"great! you executed your first code block!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CBcD9jsqPP6"
      },
      "source": [
        "## Step 1: Data Collection\n",
        "To start collecting data for training the machine learning model, follow these steps:\n",
        "\n",
        "Click on the following link: [Data Collector](https://neuralnorns.medien.ifi.lmu.de/data_collector/). This will open a P5.js script that enables you to manually enter patterns, such as drum beats.\n",
        "As you enter unique patterns, they will be automatically stored in the background.\n",
        "\n",
        "To download the collected beats, press the **download** button on the web UI.\n",
        "The downloaded file will be named **data_set.json**.\n",
        "\n",
        "**The size of your data set significantly impacts the quality and performance of your machine learning model. Generally, having a set of 200 to 400 samples is considered sufficient for basic applications.**\n",
        "\n",
        "Next, let's proceed to use the collected data for training the machine learning model. To do this:\n",
        "\n",
        "1.   Execute the next cell by clicking on the play button located in the top left corner (*visible on hover*).\n",
        "2.   Click on **choose files** to upload the trainingsdata. Navigate to your downloads folder and select the **data_set.json** file for uploading.\n",
        "\n",
        "With the data now available, we can move on to the next step and train the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "doM92mK4rlv9",
        "outputId": "0397a3ea-e987-4a9d-ea64-bdd10b62b1da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96ce0446-c985-4b8a-8d33-6aedc9ff7fb7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96ce0446-c985-4b8a-8d33-6aedc9ff7fb7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_set_4.json to data_set_4.json\n"
          ]
        }
      ],
      "source": [
        "# UPLOAD data_set.json\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dASNssjgssaW"
      },
      "source": [
        "## Step 2: Data Cleaning and Adding Variations\n",
        "Before we proceed with training the ML model, we need to prepare the data_set. The next cells will perform the following tasks:\n",
        "\n",
        "1. **Data Extraction:** The pattern raw_data will be extracted from the uploaded file, and a separate variation data object will be created. **This step is mandatory** to structure the data for training.\n",
        "\n",
        "2. **Creating Variations:** We will generate various pattern variations based on the provided patterns. These variations will involve muting active steps, permutating rows, choke rows, enforcing certain steps, and more. This step will enrich the data and enhance the model's ability to generalize.\n",
        "\n",
        "For your initial experiments, start by using the raw data without applying any variation steps. This approach will provide a baseline for the model's performance and give us a sense of how well it can learn from the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns9pxPWHBnWm",
        "outputId": "a3fd54d8-f2db-47de-c916-035a242052a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw data: 1001\n",
            "variations: 1001\n"
          ]
        }
      ],
      "source": [
        "# (1) EXTRACT DATA FROM JSON OBJECT AND CREATE VARIATION SET (MANDATORY)\n",
        "\n",
        "last_upload = list(uploaded.keys())[0]\n",
        "wrapper = io.TextIOWrapper(io.BytesIO(uploaded[last_upload]), encoding='utf-8')\n",
        "raw_data_str = wrapper.read() # FILE AS STRING\n",
        "data_set = json.loads(raw_data_str) # STRING TO JSON OBJECT\n",
        "\n",
        "width = data_set[\"w\"]\n",
        "height = data_set[\"h\"]\n",
        "raw_data = set() # a set can only contain elements that are not equal, e.g. tuples => only unique tuples\n",
        "\n",
        "for d in data_set[\"data\"]:\n",
        "  raw_data.add(to_tuple(d[\"data\"]))\n",
        "\n",
        "print(\"raw data: \"+str(len(raw_data)))\n",
        "\n",
        "# read from raw\n",
        "variations = set()\n",
        "for d in raw_data:\n",
        "  variations.add(d)\n",
        "print(\"variations:\", len(variations))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8KUpRel0mTi",
        "outputId": "4418b4b7-849a-4097-d6ae-1231b041e30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variations: 609444\n"
          ]
        }
      ],
      "source": [
        "# CREATE VARIATIONS BASED ON CARTESIAN PRODUCT (OPTIONAL)\n",
        "\n",
        "# find all patterns for each row\n",
        "patterns = [set() for i in range(height)]\n",
        "for v in variations:\n",
        "  for i in range(height):\n",
        "    patterns[i].add(v[i])\n",
        "\n",
        "# recombine all patterns via cartesian product\n",
        "comb = itertools.product(*patterns)\n",
        "variations = set()\n",
        "for el in comb:\n",
        "  variations.add(el)\n",
        "print(\"variations:\",len(variations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaxuKznw2Q1y",
        "outputId": "0f474012-fce2-4332-b7ee-0ac278f33884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variations: 361152\n"
          ]
        }
      ],
      "source": [
        "# CHOKE GROUPS (OPTIONAL)\n",
        "\n",
        "choke_groups = [(3,2)]\n",
        "\n",
        "variations = to_list(variations)\n",
        "for v in variations:\n",
        "  for gr in choke_groups:\n",
        "    lead = to_list(v[gr[0]])\n",
        "    follow = to_list(v[gr[1]])\n",
        "    v[gr[1]] = [1 if (f==1 and l!=f) else 0 for l, f in zip(lead, follow)]\n",
        "variations = to_tuple_set(variations)\n",
        "\n",
        "print(\"variations:\",len(variations))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENFORCE BEATS (OPTIONAL)\n",
        "\n",
        "enforced_patterns = [((1,0,0,0,0,0,0,0),(0,0,0,0,0,0,0,0),(0,0,0,0,0,0,0,0),(0,0,0,0,0,0,0,0))]\n",
        "\n",
        "print(enforced_patterns[0][0][0])\n",
        "\n",
        "variations = to_list(variations)\n",
        "var = []\n",
        "for v in variations:\n",
        "  for pattern in enforced_patterns:\n",
        "    lead = np.array(to_list(pattern)).flatten()\n",
        "    follow = np.array(to_list(v)).flatten()\n",
        "    flag = True\n",
        "    for l, f in zip(lead, follow):\n",
        "      if l==1 and f==0:\n",
        "        flag = False\n",
        "    if flag:\n",
        "      var.append(v)\n",
        "variations = to_tuple_set(var)\n",
        "\n",
        "print(\"variations:\",len(variations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYC7zPSxkESX",
        "outputId": "d8f5cc46-a1a7-4b29-931c-16a4c133b7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "variations: 23252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjSSVaPfoPPM",
        "outputId": "3eaae42b-ddcd-4dcb-cc90-26ce7c6fc2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variations: 4587\n"
          ]
        }
      ],
      "source": [
        "# REDUCE SIZE (OPTIONAL)\n",
        "\n",
        "factor = 0.05\n",
        "var = []\n",
        "\n",
        "for el in variations:\n",
        "  if random.random()<factor:\n",
        "    var.append(to_list(el))\n",
        "\n",
        "variations = to_tuple_set(var)\n",
        "print(\"variations:\",len(variations))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJsDbAWv7pD8",
        "outputId": "95f62aa2-e9c9-4fb6-dfcc-513a3cf5009a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variations: 46504\n"
          ]
        }
      ],
      "source": [
        "# PERMUTATE ACTIVE STEPS (OPTIONAL)\n",
        "\n",
        "def permute_triggers (d,ox,oy,_set):\n",
        "  h = len(d)\n",
        "  w = len(d[0])\n",
        "  for y in range(oy,h):\n",
        "    for x in range(ox,w):\n",
        "      if (d[y][x]) == 1:\n",
        "        n = to_list(d)\n",
        "        n[y][x] = 0\n",
        "        n = to_tuple(n)\n",
        "        _set.add(n)\n",
        "        permute_triggers(n,x,y,_set)\n",
        "\n",
        "# BIT PERMUTATIONS\n",
        "var = set()\n",
        "for d in variations:\n",
        "  permute_triggers(d,0,0,var)\n",
        "variations = variations | var\n",
        "\n",
        "print(\"variations:\",len(variations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVGcoTGR6GoG"
      },
      "source": [
        "## Step 3: Prepare Data for Training\n",
        "Before we can use the data with the machine learning model, we need to transform it into a format compatible with TensorFlow. The following steps will be performed:\n",
        "\n",
        "1. **Data Conversion:** We will convert the data into numpy arrays, a format that TensorFlow can work with efficiently.\n",
        "\n",
        "2. **Randomization and Noise Addition:** To enhance the model's ability to generalize and avoid overfitting, we will randomize the order of elements inside the arrays. Additionally, we will introduce noise to the training data, which can be adjusted as needed.\n",
        "\n",
        "By converting the data into numpy arrays and adding randomization and noise, we ensure that the model is exposed to a diverse and robust set of patterns during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n36eL1Rdz8TZ",
        "outputId": "ffc64e33-bc21-4401-d8a0-0010bbcdf1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: 1001\n"
          ]
        }
      ],
      "source": [
        "# (1) CONVERT VARIATIONS TO NUMPY ARRAY FOR ML\n",
        "\n",
        "# flatten data to 1D\n",
        "data = np.array([sum(to_list(v),[]) for v in variations])\n",
        "print(\"data:\",len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcBjZAIG8lGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa070e5-73b8-4dc5-b670-29d24154727d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: 1001\n"
          ]
        }
      ],
      "source": [
        "# (2) RANDOMIZE ORDER AND ADD NOISE\n",
        "\n",
        "# RANDOMIZE ORDER\n",
        "np.random.shuffle(data)\n",
        "print(\"data: \"+str(len(data)))\n",
        "\n",
        "# ADD NOISE\n",
        "noise_factor = 0.0\n",
        "data_noisy = data + noise_factor * tf.random.normal(shape=data.shape)\n",
        "data_noisy = tf.clip_by_value(data_noisy, clip_value_min=0., clip_value_max=1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJdJWXX9Pn7"
      },
      "source": [
        "## Step 4: Training\n",
        "In this step, we will perform the following tasks:\n",
        "\n",
        "1. **Define ML Architecture & Training:** We will define the architecture of the autoencoder, which will be used for training. The autoencoder is a neural network designed to learn efficient representations of the input data. We will run the training process using the defined architecture and the prepared data. The model will learn to generate repeating patterns based on the given data.\n",
        "\n",
        "2. **Plotting History:** After training is complete, we will plot the training history.\n",
        "\n",
        "3. **Plotting Predictions:** And visualize the model's predictions to evaluate its performance.\n",
        "\n",
        "This step is crucial in creating a model capable of generating repeating patterns effectively.\n",
        "\n",
        "Experimenting with different variations of the model architecture and training parameters can significantly impact the performance and output of the model.\n",
        "\n",
        "### Tipps:\n",
        "\n",
        "As of now, **only Sequential architectures that exclusively use dense layers are supported for export**. Additionally, to ensure proper recognition and functioning of the exported model in applications, it is crucial to name the two layers that form the output of the encoder and the input of the decoder as **latent** and **decoder**, respectively.\n",
        "\n",
        "In order to normalize the vector dimensions to values between 0 and 1, it is essential to utilize the **sigmoid** activation function for both the output layer of the encoder and the output layer of the decoder in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o44ghe-LId7m",
        "outputId": "fff0c1b6-0095-4b61-d797-c784b8fedc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "125/125 [==============================] - 3s 7ms/step - loss: 0.1730 - accuracy: 0.8460 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
            "Epoch 2/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1328 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 1.0000\n",
            "Epoch 3/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
            "Epoch 4/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 5/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 6/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
            "Epoch 7/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
            "Epoch 8/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 1.0000\n",
            "Epoch 9/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
            "Epoch 10/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
            "Epoch 11/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
            "Epoch 12/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1315 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
            "Epoch 13/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1292 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 1.0000\n",
            "Epoch 14/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
            "Epoch 15/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1203 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
            "Epoch 16/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 1.0000\n",
            "Epoch 17/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 1.0000\n",
            "Epoch 18/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
            "Epoch 19/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
            "Epoch 20/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
            "Epoch 21/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
            "Epoch 22/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
            "Epoch 23/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9960 - val_loss: 0.0917 - val_accuracy: 0.9860\n",
            "Epoch 30/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9840 - val_loss: 0.0906 - val_accuracy: 0.9780\n",
            "Epoch 31/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9620 - val_loss: 0.0904 - val_accuracy: 0.9601\n",
            "Epoch 32/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9580 - val_loss: 0.0893 - val_accuracy: 0.9601\n",
            "Epoch 33/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0900 - accuracy: 0.9560 - val_loss: 0.0887 - val_accuracy: 0.9581\n",
            "Epoch 34/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0894 - accuracy: 0.9540 - val_loss: 0.0884 - val_accuracy: 0.9601\n",
            "Epoch 35/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9520 - val_loss: 0.0880 - val_accuracy: 0.9601\n",
            "Epoch 36/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9480 - val_loss: 0.0878 - val_accuracy: 0.9441\n",
            "Epoch 37/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9380 - val_loss: 0.0871 - val_accuracy: 0.9441\n",
            "Epoch 38/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9300 - val_loss: 0.0867 - val_accuracy: 0.9361\n",
            "Epoch 39/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0861 - accuracy: 0.9240 - val_loss: 0.0866 - val_accuracy: 0.9202\n",
            "Epoch 40/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9200 - val_loss: 0.0856 - val_accuracy: 0.8962\n",
            "Epoch 41/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9080 - val_loss: 0.0853 - val_accuracy: 0.8842\n",
            "Epoch 42/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0843 - accuracy: 0.9060 - val_loss: 0.0844 - val_accuracy: 0.8962\n",
            "Epoch 43/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9080 - val_loss: 0.0842 - val_accuracy: 0.8882\n",
            "Epoch 44/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0834 - accuracy: 0.8940 - val_loss: 0.0838 - val_accuracy: 0.8942\n",
            "Epoch 45/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.8860 - val_loss: 0.0837 - val_accuracy: 0.8822\n",
            "Epoch 46/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0822 - accuracy: 0.8580 - val_loss: 0.0836 - val_accuracy: 0.8982\n",
            "Epoch 47/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.8520 - val_loss: 0.0838 - val_accuracy: 0.8403\n",
            "Epoch 48/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.8560 - val_loss: 0.0830 - val_accuracy: 0.8663\n",
            "Epoch 49/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0806 - accuracy: 0.8560 - val_loss: 0.0826 - val_accuracy: 0.8743\n",
            "Epoch 50/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.8660 - val_loss: 0.0820 - val_accuracy: 0.8882\n",
            "Epoch 51/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.8720 - val_loss: 0.0820 - val_accuracy: 0.9002\n",
            "Epoch 52/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.8600 - val_loss: 0.0822 - val_accuracy: 0.8603\n",
            "Epoch 53/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.8940 - val_loss: 0.0813 - val_accuracy: 0.9082\n",
            "Epoch 54/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.8740 - val_loss: 0.0810 - val_accuracy: 0.9182\n",
            "Epoch 55/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0786 - accuracy: 0.8840 - val_loss: 0.0816 - val_accuracy: 0.9202\n",
            "Epoch 56/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0779 - accuracy: 0.8880 - val_loss: 0.0811 - val_accuracy: 0.8643\n",
            "Epoch 57/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0778 - accuracy: 0.8900 - val_loss: 0.0805 - val_accuracy: 0.8802\n",
            "Epoch 58/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0771 - accuracy: 0.8880 - val_loss: 0.0814 - val_accuracy: 0.9082\n",
            "Epoch 59/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.8840 - val_loss: 0.0807 - val_accuracy: 0.9202\n",
            "Epoch 60/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.9020 - val_loss: 0.0800 - val_accuracy: 0.8882\n",
            "Epoch 61/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.8860 - val_loss: 0.0796 - val_accuracy: 0.8942\n",
            "Epoch 62/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.8900 - val_loss: 0.0796 - val_accuracy: 0.8882\n",
            "Epoch 63/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0761 - accuracy: 0.8900 - val_loss: 0.0806 - val_accuracy: 0.8942\n",
            "Epoch 64/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.8900 - val_loss: 0.0792 - val_accuracy: 0.8862\n",
            "Epoch 65/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.8840 - val_loss: 0.0795 - val_accuracy: 0.9002\n",
            "Epoch 66/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.8900 - val_loss: 0.0794 - val_accuracy: 0.9162\n",
            "Epoch 67/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.8860 - val_loss: 0.0790 - val_accuracy: 0.8802\n",
            "Epoch 68/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.8920 - val_loss: 0.0796 - val_accuracy: 0.9062\n",
            "Epoch 69/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.8880 - val_loss: 0.0787 - val_accuracy: 0.9022\n",
            "Epoch 70/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0748 - accuracy: 0.8860 - val_loss: 0.0782 - val_accuracy: 0.8922\n",
            "Epoch 71/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.8980 - val_loss: 0.0785 - val_accuracy: 0.8802\n",
            "Epoch 72/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.8840 - val_loss: 0.0786 - val_accuracy: 0.9022\n",
            "Epoch 73/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.8760 - val_loss: 0.0786 - val_accuracy: 0.8842\n",
            "Epoch 74/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.8860 - val_loss: 0.0784 - val_accuracy: 0.9022\n",
            "Epoch 75/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.8880 - val_loss: 0.0793 - val_accuracy: 0.9022\n",
            "Epoch 76/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.8820 - val_loss: 0.0784 - val_accuracy: 0.8942\n",
            "Epoch 77/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.8660 - val_loss: 0.0788 - val_accuracy: 0.8902\n",
            "Epoch 78/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0736 - accuracy: 0.8740 - val_loss: 0.0783 - val_accuracy: 0.8762\n",
            "Epoch 79/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.8740 - val_loss: 0.0783 - val_accuracy: 0.8882\n",
            "Epoch 80/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.8680 - val_loss: 0.0780 - val_accuracy: 0.8842\n",
            "Epoch 81/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.8820 - val_loss: 0.0783 - val_accuracy: 0.9022\n",
            "Epoch 82/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.8680 - val_loss: 0.0789 - val_accuracy: 0.8902\n",
            "Epoch 83/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.8880 - val_loss: 0.0782 - val_accuracy: 0.8942\n",
            "Epoch 84/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0730 - accuracy: 0.8740 - val_loss: 0.0794 - val_accuracy: 0.9142\n",
            "Epoch 85/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.8700 - val_loss: 0.0779 - val_accuracy: 0.8962\n",
            "Epoch 86/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.8800 - val_loss: 0.0781 - val_accuracy: 0.8882\n",
            "Epoch 87/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.8880 - val_loss: 0.0782 - val_accuracy: 0.8762\n",
            "Epoch 88/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.8880 - val_loss: 0.0784 - val_accuracy: 0.9022\n",
            "Epoch 89/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0724 - accuracy: 0.8840 - val_loss: 0.0781 - val_accuracy: 0.9242\n",
            "Epoch 90/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.9000 - val_loss: 0.0786 - val_accuracy: 0.9222\n",
            "Epoch 91/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.8880 - val_loss: 0.0780 - val_accuracy: 0.9281\n",
            "Epoch 92/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.8960 - val_loss: 0.0781 - val_accuracy: 0.9222\n",
            "Epoch 93/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9020 - val_loss: 0.0776 - val_accuracy: 0.9142\n",
            "Epoch 94/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9000 - val_loss: 0.0782 - val_accuracy: 0.9162\n",
            "Epoch 95/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9140 - val_loss: 0.0773 - val_accuracy: 0.9222\n",
            "Epoch 96/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0719 - accuracy: 0.9120 - val_loss: 0.0779 - val_accuracy: 0.9182\n",
            "Epoch 97/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9120 - val_loss: 0.0783 - val_accuracy: 0.9281\n",
            "Epoch 98/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9200 - val_loss: 0.0785 - val_accuracy: 0.9022\n",
            "Epoch 99/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9200 - val_loss: 0.0780 - val_accuracy: 0.9162\n",
            "Epoch 100/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0715 - accuracy: 0.9240 - val_loss: 0.0775 - val_accuracy: 0.9461\n",
            "Epoch 101/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9300 - val_loss: 0.0775 - val_accuracy: 0.9321\n",
            "Epoch 102/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9220 - val_loss: 0.0774 - val_accuracy: 0.9401\n",
            "Epoch 103/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9540 - val_loss: 0.0779 - val_accuracy: 0.9661\n",
            "Epoch 104/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0712 - accuracy: 0.9380 - val_loss: 0.0773 - val_accuracy: 0.9401\n",
            "Epoch 105/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0715 - accuracy: 0.9460 - val_loss: 0.0776 - val_accuracy: 0.9581\n",
            "Epoch 106/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9480 - val_loss: 0.0776 - val_accuracy: 0.9561\n",
            "Epoch 107/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9600 - val_loss: 0.0775 - val_accuracy: 0.9461\n",
            "Epoch 108/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9340 - val_loss: 0.0776 - val_accuracy: 0.9441\n",
            "Epoch 109/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9720 - val_loss: 0.0786 - val_accuracy: 0.9361\n",
            "Epoch 110/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0708 - accuracy: 0.9560 - val_loss: 0.0772 - val_accuracy: 0.9601\n",
            "Epoch 111/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9580 - val_loss: 0.0792 - val_accuracy: 0.9760\n",
            "Epoch 112/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0707 - accuracy: 0.9620 - val_loss: 0.0777 - val_accuracy: 0.9561\n",
            "Epoch 113/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.0772 - val_accuracy: 0.9681\n",
            "Epoch 114/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9800 - val_loss: 0.0789 - val_accuracy: 0.9780\n",
            "Epoch 115/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0701 - accuracy: 0.9740 - val_loss: 0.0770 - val_accuracy: 0.9721\n",
            "Epoch 116/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9800 - val_loss: 0.0769 - val_accuracy: 0.9800\n",
            "Epoch 117/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9820 - val_loss: 0.0769 - val_accuracy: 0.9800\n",
            "Epoch 118/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0704 - accuracy: 0.9780 - val_loss: 0.0774 - val_accuracy: 0.9760\n",
            "Epoch 119/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0703 - accuracy: 0.9860 - val_loss: 0.0773 - val_accuracy: 0.9701\n",
            "Epoch 120/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0701 - accuracy: 0.9820 - val_loss: 0.0770 - val_accuracy: 0.9800\n",
            "Epoch 121/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9860 - val_loss: 0.0768 - val_accuracy: 0.9920\n",
            "Epoch 122/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9860 - val_loss: 0.0768 - val_accuracy: 0.9900\n",
            "Epoch 123/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 0.9900 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0697 - accuracy: 0.9960 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9920 - val_loss: 0.0765 - val_accuracy: 0.9980\n",
            "Epoch 126/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# (1) ML MODEL ARCHITECTURE\n",
        "\n",
        "latent_dim = 2\n",
        "hidden_dim = 64\n",
        "output_dim = width*height\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(hidden_dim, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(hidden_dim, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(latent_dim, activation='sigmoid', name=\"latent\"))\n",
        "model.add(tf.keras.layers.Dense(hidden_dim, activation='relu', name=\"decoder\"))\n",
        "model.add(tf.keras.layers.Dense(hidden_dim, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(output_dim, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.MeanSquaredError(), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(data_noisy, data,validation_split = 0.5, epochs=500, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "WauTjyhfp8G4",
        "outputId": "c0d35c85-ac52-4278-b17b-ec07a8ad333d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# PLOT TRAINING HISTORY\n",
        "\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model: loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation', 'accuracy'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "q8jrfUqS_-Eg",
        "outputId": "e718b036-72a5-43b1-c218-1a7bfe98f7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 24 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# (3) PLOT MODEL PREDICTIONS\n",
        "\n",
        "decoded_imgs = model.predict(data)\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "n = 8\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(3, n, i + 1 + 0*n)\n",
        "  img = data[i].reshape(height,width)\n",
        "  img = np.flipud(img)\n",
        "  plt.imshow(img)\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display output vector\n",
        "  ax = plt.subplot(3, n, i + 1 + 1*n)\n",
        "  a = decoded_imgs[i].reshape(height,width)\n",
        "  a = np.flipud(a)\n",
        "  plt.imshow(a)\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display output vector + threshold\n",
        "  ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "  b = np.where(a>0.4,1,0)\n",
        "  plt.imshow(b)\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWL8v7FTGUTr"
      },
      "source": [
        "## Step 5: Export\n",
        "Congratulations on training your model! Now that the model is ready, you can proceed with exporting it for further use in various applications. Here's how you can do it:\n",
        "\n",
        "1. **Export as JSON:** Save the trained model as a JSON file. This file can be utilized in a P5.js test application or in a Norns script, allowing you to generate repeating patterns in those environments.\n",
        "\n",
        "2. Click on the **files** tab located on the left-hand side of the Colab interface. This will open a file explorer where you can manage your files.\n",
        "\n",
        "3. Locate the file named model.json, which represents your trained model. It is stored in the **content** folder.\n",
        "\n",
        "4. Right-click on the **model.json** file and select \"Download\" from the context menu.\n",
        "\n",
        "By downloading the model.json file, you ensure that your trained model is securely saved and can be accessed for future use or further experimentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5GGrSg4t5dR"
      },
      "outputs": [],
      "source": [
        "# (1) EXPORT MODEL AS JSON FILE\n",
        "\n",
        "json_obj = json.loads(model.to_json())\n",
        "\n",
        "json_obj[\"width\"] = width\n",
        "json_obj[\"height\"] = height\n",
        "\n",
        "for layer in json_obj[\"config\"][\"layers\"]:\n",
        "  try:\n",
        "    layer[\"weights\"] = model.get_layer(layer[\"config\"][\"name\"]).get_weights()[0].tolist()\n",
        "    layer[\"bias\"] = model.get_layer(layer[\"config\"][\"name\"]).get_weights()[1].tolist()\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open('model.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(json_obj, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgumPQnYrB3W"
      },
      "source": [
        "# Step 6: test model\n",
        "\n",
        "The following P5 script allows you to test your trained model. Simply open the [ModelReader](https://neuralnorns.medien.ifi.lmu.de/model_reader/) and drag and drop the **model.json** file."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}